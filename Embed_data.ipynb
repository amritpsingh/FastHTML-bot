{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "247b048b-558c-41a4-88e5-131ea141fb81",
   "metadata": {},
   "source": [
    "## Create Embeddings & Store in Vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b879c923-3a19-4669-8ee3-208dd8ce6610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict\n",
    "import uuid\n",
    "\n",
    "# Import the markdown processing functions\n",
    "from markdown_processor_debug import process_all_markdown_files\n",
    "\n",
    "\n",
    "def create_embeddings_and_store(chunks: List[Dict[str, str]], collection_name: str = \"fasthtml_docs\"):\n",
    "    # Initialize Chroma client\n",
    "    client = chromadb.Client()\n",
    "\n",
    "    # Create a collection\n",
    "    embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
    "    collection = client.create_collection(name=collection_name, embedding_function=embedding_function)\n",
    "\n",
    "    # Initialize the embedding model\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    # Prepare data for Chroma\n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        documents.append(chunk['text'])\n",
    "        metadatas.append({\"source\": chunk['source']})\n",
    "        ids.append(str(uuid.uuid4()))  # Generate a unique ID for each chunk\n",
    "\n",
    "    # Create embeddings\n",
    "    embeddings = model.encode(documents)\n",
    "\n",
    "    # Add to Chroma DB\n",
    "    collection.add(\n",
    "        documents=documents,\n",
    "        embeddings=embeddings.tolist(),\n",
    "        metadatas=metadatas,\n",
    "        ids=ids\n",
    "    )\n",
    "\n",
    "    print(f\"Added {len(documents)} chunks to Chroma DB collection '{collection_name}'\")\n",
    "\n",
    "    return collection\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Process markdown files and get chunks\n",
    "    directory = './docs/DocsFasthtMl'\n",
    "    base_url = 'https://docs.fastht.ml'\n",
    "    \n",
    "    print(f\"Processing directory: {directory}\")\n",
    "    print(f\"Base URL: {base_url}\")\n",
    "    \n",
    "    all_chunks = process_all_markdown_files(directory, base_url)\n",
    "    print(f\"Total chunks extracted: {len(all_chunks)}\")\n",
    "\n",
    "    if all_chunks:\n",
    "        # Create embeddings and store in Chroma DB\n",
    "        collection = create_embeddings_and_store(all_chunks)\n",
    "\n",
    "        # Example query to test the embeddings\n",
    "        query = \"What is FastHTML?\"\n",
    "        results = collection.query(\n",
    "            query_texts=[query],\n",
    "            n_results=2\n",
    "        )\n",
    "\n",
    "        print(\"\\nExample query results:\")\n",
    "        for i, (document, metadata) in enumerate(zip(results['documents'][0], results['metadatas'][0])):\n",
    "            print(f\"\\nResult {i+1}:\")\n",
    "            print(f\"Source: {metadata['source']}\")\n",
    "            print(f\"Text: {document[:200]}...\")  # Print first 200 characters\n",
    "    else:\n",
    "        print(\"No chunks were extracted. Please check your markdown files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
