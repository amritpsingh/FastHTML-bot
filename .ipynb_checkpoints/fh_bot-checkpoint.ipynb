{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c759d918-fc95-4589-8415-40ef09162b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import logging\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "\n",
    "from config.settings import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "700da9b0-203e-49df-bfce-2ecb3099c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f699d3f1-720e-48e6-8a9d-8024e809b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sections(soup: BeautifulSoup, uri: str) -> List[Dict]:\n",
    "        sections = soup.find_all(\"section\")\n",
    "        section_list = []\n",
    "        for i, section in enumerate(sections):\n",
    "            section_id = section.get(\"id\")\n",
    "            section_text = extract_text_from_section(section)\n",
    "            if section_id:\n",
    "                section_data = {\n",
    "                    \"source\": f\"{uri}#{section_id}\",\n",
    "                    \"text\": section_text,\n",
    "                    \"previous_section\": section_list[i-1]['source'] if i > 0 else None,\n",
    "                    \"next_section\": None,\n",
    "                    \"metadata\": {\n",
    "                        \"page_heading\": soup.find(\"h1\").get_text().strip() if soup.find(\"h1\") else Path(uri).stem,\n",
    "                        \"section_id\": section_id\n",
    "                    }\n",
    "                }\n",
    "                if i > 0:\n",
    "                    section_list[i-1]['next_section'] = section_data['source']\n",
    "                section_list.append(section_data)\n",
    "        return section_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8758ed1f-1526-4b4d-9584-2e56abba24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_section(section) -> str:\n",
    "        texts = []\n",
    "        for element in section.children:\n",
    "            if isinstance(element, NavigableString):\n",
    "                if element.strip():\n",
    "                    texts.append(element.strip())\n",
    "            elif element.name != 'section':\n",
    "                texts.append(element.get_text().strip())\n",
    "        return clean_text(\" \".join(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccd72f2a-629d-49cb-9c2a-a33a59443bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_uri(path: Path, scheme: str = \"https://\", domain: str = \"docs.fastht.ml\") -> str:\n",
    "        relative_path = str(path.relative_to(settings.RAW_DATA_DIR)).replace(\"\\\\\", \"/\")\n",
    "        return scheme + domain + \"/\" + relative_path\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    # Replace multiple newlines with a single space\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "\n",
    "def process_html_files(html_files_path: List[Path]) -> List[Dict]:\n",
    "    docs_text = []\n",
    "    for record in html_files_path:\n",
    "        print(\"processing: \", record)\n",
    "        with open(record, \"r\", encoding=\"utf-8\") as html_file:\n",
    "            soup = BeautifulSoup(html_file, \"html.parser\")\n",
    "        uri = path_to_uri(path=record)\n",
    "        sections = extract_sections(soup, uri)\n",
    "        docs_text.append(sections)\n",
    "    return docs_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d48e92a-5949-47aa-9d48-225fe83de36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/index.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/ref/defining_xt_component.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/ref/live_reload.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/ref/handlers.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/api/oauth.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/api/core.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/api/cli.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/api/fastapp.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/api/components.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/api/xtend.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/api/js.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/api/pico.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/tutorials/tutorial_for_web_devs.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/tutorials/e2e.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/tutorials/quickstart_for_web_devs.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/tutorials/by_example.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/tutorials/index.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/explains/oauth.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/explains/faq.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/explains/explaining_xt_components.html\n",
      "processing:  /home/amrit/data-projects/llms/fasthtml-docs-bot/data/raw-data/explains/routes.html\n",
      "Total documents processed: 21\n"
     ]
    }
   ],
   "source": [
    "html_files_path = [path for path in settings.RAW_DATA_DIR.rglob(\"*.html\") if not path.is_dir()]\n",
    "docs_text = process_html_files(html_files_path)\n",
    "print(f\"Total documents processed: {len(docs_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c353758-10ea-48b6-b800-acc6e33975f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'source': 'https://docs.fastht.ml/index.html#installation',\n",
       "   'text': 'Installation Since fasthtml is a Python library, you can install it with: pip install python-fasthtml In the near future, we hope to add component libraries that can likewise be installed via pip .',\n",
       "   'previous_section': None,\n",
       "   'next_section': 'https://docs.fastht.ml/index.html#usage',\n",
       "   'metadata': {'page_heading': 'FastHTML', 'section_id': 'installation'}},\n",
       "  {'source': 'https://docs.fastht.ml/index.html#usage',\n",
       "   'text': 'Usage For a minimal app, create a file “main.py” as follows: main.py from fasthtml.common import * app,rt = fast_app() @rt(\\'/\\') def get(): return Div(P(\\'Hello World!\\'), hx_get=\"/change\") serve() Running the app with python main.py prints out a link to your running app: http://localhost:5001 . Visit that link in your browser and you should see a page with the text “Hello World!”. Congratulations, you’ve just created your first FastHTML app! Adding interactivity is surprisingly easy, thanks to HTMX. Modify the file to add this function: main.py @rt(\\'/change\\') def get(): return P(\\'Nice to be here!\\') You now have a page with a clickable element that changes the text when clicked. When clicking on this link, the server will respond with an “HTML partial”—that is, just a snippet of HTML which will be inserted into the existing page. In this case, the returned element will replace the original P element (since that’s the default behavior of HTMX) with the new version returned by the second route. This “hypermedia-based” approach to web development is a powerful way to build web applications.',\n",
       "   'previous_section': 'https://docs.fastht.ml/index.html#installation',\n",
       "   'next_section': 'https://docs.fastht.ml/index.html#getting-help-from-ai',\n",
       "   'metadata': {'page_heading': 'FastHTML', 'section_id': 'usage'}},\n",
       "  {'source': 'https://docs.fastht.ml/index.html#getting-help-from-ai',\n",
       "   'text': 'Getting help from AI Because FastHTML is newer than most LLMs, AI systems like Cursor, ChatGPT, Claude, and Copilot won’t give useful answers about it. To fix that problem, we’ve provided an LLM-friendly guide that teaches them how to use FastHTML. To use it, add this link for your AI helper to use: /llms-ctx.txt This example is in a format based on recommendations from Anthropic for use with Claude Projects . This works so well that we’ve actually found that Claude can provide even better information than our own documentation! For instance, read through this annotated Claude chat for some great getting-started information, entirely generated from a project using the above text file as context. If you use Cursor, type @doc then choose “ Add new doc ”, and use the /llms-ctx.txt link above. The context file is auto-generated from our llms.txt (our proposed standard for providing AI-friendly information)—you can generate alternative versions suitable for other models as needed.',\n",
       "   'previous_section': 'https://docs.fastht.ml/index.html#usage',\n",
       "   'next_section': 'https://docs.fastht.ml/index.html#next-steps',\n",
       "   'metadata': {'page_heading': 'FastHTML',\n",
       "    'section_id': 'getting-help-from-ai'}},\n",
       "  {'source': 'https://docs.fastht.ml/index.html#next-steps',\n",
       "   'text': 'Next Steps Start with the official sources to learn more about FastHTML: About : Learn about the core ideas behind FastHTML Documentation : Learn from examples how to write FastHTML code Idiomatic app : Heavily commented source code walking through a complete application, including custom authentication, JS library connections, and database use. We also have a 1-hour intro video: The capabilities of FastHTML are vast and growing, and not all the features and patterns have been documented yet. Be prepared to invest time into studying and modifying source code, such as the main FastHTML repo’s notebooks and the official FastHTML examples repo: FastHTML Examples Repo on GitHub FastHTML Repo on GitHub Then explore the small but growing third-party ecosystem of FastHTML tutorials, notebooks, libraries, and components: FastHTML Gallery : Learn from minimal examples of components (ie chat bubbles, click-to-edit, infinite scroll, etc) Creating Custom FastHTML Tags for Markdown Rendering by Isaac Flath Your tutorial here! Finally, join the FastHTML community to ask questions, share your work, and learn from others: Discord',\n",
       "   'previous_section': 'https://docs.fastht.ml/index.html#getting-help-from-ai',\n",
       "   'next_section': None,\n",
       "   'metadata': {'page_heading': 'FastHTML', 'section_id': 'next-steps'}}]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_text[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e91fcc93-2fbc-405a-bf6b-465affd8eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc5be52f-7589-4867-9ff0-b77a2d531b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, chunk_size: int, chunk_overlap: int):\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            length_function=len\n",
    "        )\n",
    "\n",
    "    def chunk_section(self, section: Dict[str, str]) -> List[Dict[str, str]]:\n",
    "        chunks = self.text_splitter.create_documents(\n",
    "            texts=[section[\"text\"]],\n",
    "            metadatas=[{\n",
    "                \"source\": section[\"source\"],\n",
    "                \"previous_section\": section.get(\"previous_section\"),\n",
    "                \"next_section\": section.get(\"next_section\"),\n",
    "                \"metadata\": section.get(\"metadata\")\n",
    "            }]\n",
    "        )\n",
    "        return [{\n",
    "            \"text\": chunk.page_content,\n",
    "            \"source\": chunk.metadata[\"source\"],\n",
    "            \"previous_section\": chunk.metadata[\"previous_section\"],\n",
    "            \"next_section\": chunk.metadata[\"next_section\"],\n",
    "            \"metadata\": chunk.metadata[\"metadata\"]\n",
    "        } for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2101620-9360-4d92-8ec6-359bccbd8556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 534\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    preprocessor = Preprocessor(chunk_size=settings.CHUNK_SIZE, chunk_overlap=settings.CHUNK_OVERLAP)\n",
    "    chunked_docs_text = []\n",
    "    for doc in docs_text:\n",
    "        for section in doc:\n",
    "            chunked_sections = preprocessor.chunk_section(section)\n",
    "            chunked_docs_text.extend(chunked_sections)\n",
    "    \n",
    "    print(f\"Total chunks created: {len(chunked_docs_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "800dd40f-05ec-40d0-8d69-9dd083488eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Installation Since fasthtml is a Python library, you can install it with: pip install python-fasthtml In the near future, we hope to add component libraries that can likewise be installed via pip .',\n",
       "  'source': 'https://docs.fastht.ml/index.html#installation',\n",
       "  'previous_section': None,\n",
       "  'next_section': 'https://docs.fastht.ml/index.html#usage',\n",
       "  'metadata': {'page_heading': 'FastHTML', 'section_id': 'installation'}},\n",
       " {'text': 'Usage For a minimal app, create a file “main.py” as follows: main.py from fasthtml.common import * app,rt = fast_app() @rt(\\'/\\') def get(): return Div(P(\\'Hello World!\\'), hx_get=\"/change\") serve() Running the app with python main.py prints out a link to your running app: http://localhost:5001 . Visit that link in your browser and you should see a page with the text “Hello World!”. Congratulations, you’ve just created your first FastHTML app! Adding interactivity is surprisingly easy, thanks to',\n",
       "  'source': 'https://docs.fastht.ml/index.html#usage',\n",
       "  'previous_section': 'https://docs.fastht.ml/index.html#installation',\n",
       "  'next_section': 'https://docs.fastht.ml/index.html#getting-help-from-ai',\n",
       "  'metadata': {'page_heading': 'FastHTML', 'section_id': 'usage'}},\n",
       " {'text': \"interactivity is surprisingly easy, thanks to HTMX. Modify the file to add this function: main.py @rt('/change') def get(): return P('Nice to be here!') You now have a page with a clickable element that changes the text when clicked. When clicking on this link, the server will respond with an “HTML partial”—that is, just a snippet of HTML which will be inserted into the existing page. In this case, the returned element will replace the original P element (since that’s the default behavior of\",\n",
       "  'source': 'https://docs.fastht.ml/index.html#usage',\n",
       "  'previous_section': 'https://docs.fastht.ml/index.html#installation',\n",
       "  'next_section': 'https://docs.fastht.ml/index.html#getting-help-from-ai',\n",
       "  'metadata': {'page_heading': 'FastHTML', 'section_id': 'usage'}},\n",
       " {'text': 'P element (since that’s the default behavior of HTMX) with the new version returned by the second route. This “hypermedia-based” approach to web development is a powerful way to build web applications.',\n",
       "  'source': 'https://docs.fastht.ml/index.html#usage',\n",
       "  'previous_section': 'https://docs.fastht.ml/index.html#installation',\n",
       "  'next_section': 'https://docs.fastht.ml/index.html#getting-help-from-ai',\n",
       "  'metadata': {'page_heading': 'FastHTML', 'section_id': 'usage'}},\n",
       " {'text': 'Getting help from AI Because FastHTML is newer than most LLMs, AI systems like Cursor, ChatGPT, Claude, and Copilot won’t give useful answers about it. To fix that problem, we’ve provided an LLM-friendly guide that teaches them how to use FastHTML. To use it, add this link for your AI helper to use: /llms-ctx.txt This example is in a format based on recommendations from Anthropic for use with Claude Projects . This works so well that we’ve actually found that Claude can provide even better',\n",
       "  'source': 'https://docs.fastht.ml/index.html#getting-help-from-ai',\n",
       "  'previous_section': 'https://docs.fastht.ml/index.html#usage',\n",
       "  'next_section': 'https://docs.fastht.ml/index.html#next-steps',\n",
       "  'metadata': {'page_heading': 'FastHTML',\n",
       "   'section_id': 'getting-help-from-ai'}}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_docs_text[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bebf23ef-1d57-460e-9c15-5eee962d7058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "804349e9-ddb9-45ad-8b78-4b08fdd67f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_embedding_model: Returns an embedding model based on the specified model name.\n",
    "# OpenAIEmbeddings: Uses OpenAI’s API for embedding.\n",
    "# HuggingFaceEmbeddings: Uses Hugging Face’s models for embedding.\n",
    "\n",
    "def get_embedding_model(embedding_model_name, model_kwargs, encode_kwargs):\n",
    "    if embedding_model_name == \"text-embedding-ada-002\":\n",
    "        embedding_model = OpenAIEmbeddings(\n",
    "            model = embedding_model_name,\n",
    "            openai_api_base = os.environ[\"OPENAI_API_BASE\"],\n",
    "            openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "        )\n",
    "    else:\n",
    "        embedding_model = HuggingFaceEmbeddings(\n",
    "            model_name = embedding_model_name, # also works with model_path\n",
    "            model_kwargs = model_kwargs,\n",
    "            encode_kwargs = encode_kwargs\n",
    "        )\n",
    "    return embedding_model\n",
    "\n",
    "# EmbedChunks: A class to embed chunks using the specified model.\n",
    "# init: Initializes the embedding model.\n",
    "# call: Embeds the text in the batch and returns the embeddings along with the original text and source.\n",
    "\n",
    "class EmbedChunks:\n",
    "    def __init__(self, model_name):\n",
    "        self.embedding_model = get_embedding_model(\n",
    "            embedding_model_name = model_name,\n",
    "            model_kwargs = {\"device\": \"cuda\"},\n",
    "            encode_kwargs = {\"device\": \"cuda\", \"batch_size\": 100}\n",
    "        )\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        embeddings = self.embedding_model.embed_documents(batch[\"text\"])\n",
    "        return {\"text\": batch[\"text\"], \"source\": batch[\"source\"], \"embeddings\": embeddings}\n",
    "\n",
    "\n",
    "class Embedder:\n",
    "    def __init__(self, model_name: str):\n",
    "        self.embedding_model = get_embedding_model(\n",
    "            model_name=model_name,\n",
    "            model_kwargs={\"device\": \"cuda\"},\n",
    "            encode_kwargs={\"device\": \"cuda\", \"batch_size\": 100}\n",
    "        )\n",
    "\n",
    "    def embed_chunks(self, chunks: List[Dict[str, str]]) -> List[Dict[str, str]]:\n",
    "        texts = [chunk[\"text\"] for chunk in chunks]\n",
    "        embeddings = self.embedding_model.embed_documents(texts)\n",
    "        return [\n",
    "            {\"text\": chunk[\"text\"], \"source\": chunk[\"source\"], \"embedding\": embedding}\n",
    "            for chunk, embedding in zip(chunks, embeddings)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46727545-0b5b-4a82-bde2-aa25ccac8b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amrit/miniforge3/envs/llmdev/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "INFO:datasets:PyTorch version 2.4.1 available.\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: thenlper/gte-base\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings created: 534\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    embedder = Embedder(model_name=settings.EMBEDDING_MODEL_NAME)\n",
    "    embedded_chunks = embedder.embed_chunks(chunked_docs_text)\n",
    "\n",
    "    print(f\"Total embeddings created: {len(embedded_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "18083687-87cb-4f2f-80cc-a694d7adc6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/storage/vector_store.py\n",
    "import os\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0c96dcd5-c176-4f12-940a-9eb64b9142a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "    def __init__(self, embedding_model, persist_directory: Path):\n",
    "        self.vector_store = Chroma(\n",
    "            collection_name=\"fasthtml_docs_db\",\n",
    "            embedding_function=embedding_model,\n",
    "            persist_directory=os.path.abspath(persist_directory)\n",
    "        )\n",
    "\n",
    "    def add_documents(self, documents: List[Dict[str, str]]):\n",
    "        docs = [\n",
    "            Document(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"]})\n",
    "            for doc in documents\n",
    "        ]\n",
    "        self.vector_store.add_documents(docs)\n",
    "        logger.info(f\"Added {len(docs)} documents to the vector store\")\n",
    "\n",
    "    def similarity_search(self, query: str, k: int = 5) -> List[Dict[str, str]]:\n",
    "        results = self.vector_store.similarity_search_with_score(query, k=k)\n",
    "        return [\n",
    "            {\n",
    "                \"text\": doc.page_content,\n",
    "                \"source\": doc.metadata.get(\"source\", \"\"),\n",
    "                \"score\": score\n",
    "            }\n",
    "            for doc, score in results\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0ad96989-bc50-4480-ae4b-df40f77b2338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: thenlper/gte-base\n",
      "INFO:chromadb.telemetry.posthog:Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items in name='fasthtml_docs_db' id=UUID('f5836f62-38aa-40d4-add4-b2b4d063ece3') metadata=None: 534\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize the embedding model\n",
    "    embedding_model = HuggingFaceEmbeddings(\n",
    "        model_name=settings.EMBEDDING_MODEL_NAME,\n",
    "        model_kwargs={\"device\": \"cuda\"},\n",
    "        encode_kwargs={\"device\": \"cuda\", \"batch_size\": 100}\n",
    "    )\n",
    "\n",
    "    # Initialize the vector store\n",
    "    vectorStore = VectorStore(embedding_model=embedding_model, persist_directory=settings.VECTOR_STORE_DIR)\n",
    "    \n",
    "    # Assuming embedded_chunks is already defined and contains the embedded documents\n",
    "    vectorStore.add_documents(embedded_chunks)\n",
    "\n",
    "    # Assuming you have a client instance to interact with the Chroma DB\n",
    "    client = vectorStore.vector_store._client\n",
    "    collection = client.get_collection(name=\"fasthtml_docs_db\")\n",
    "\n",
    "    print(f\"Total items in {collection}: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fb17802-f39a-41a4-91b5-1bec626e147c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Installing FastHTML FastHTML is just Python . Installation is often done with pip: pip install python-fasthtml',\n",
       "  'source': 'https://docs.fastht.ml/tutorials/tutorial_for_web_devs.html#installing-fasthtml',\n",
       "  'score': 0.1384994089603424},\n",
       " {'text': 'Install FastHTML For Mac, Windows and Linux, enter: pip install python-fasthtml',\n",
       "  'source': 'https://docs.fastht.ml/tutorials/e2e.html#install-fasthtml',\n",
       "  'score': 0.1573334038257599},\n",
       " {'text': 'Installation pip install python-fasthtml',\n",
       "  'source': 'https://docs.fastht.ml/tutorials/quickstart_for_web_devs.html#installation',\n",
       "  'score': 0.1606634110212326},\n",
       " {'text': 'Installation Since fasthtml is a Python library, you can install it with: pip install python-fasthtml In the near future, we hope to add component libraries that can likewise be installed via pip .',\n",
       "  'source': 'https://docs.fastht.ml/index.html#installation',\n",
       "  'score': 0.1731264591217041},\n",
       " {'text': 'FastHTML Basics FastHTML is just Python . You can install it with pip install python-fasthtml . Extensions/components built for it can likewise be distributed via PyPI or as simple Python files. The core usage of FastHTML is to define routes, and then to define what to do at each route. This is similar to the FastAPI web framework (in fact we implemented much of the functionality to match the FastAPI usage examples), but where FastAPI focuses on returning JSON data to build APIs, FastHTML',\n",
       "  'source': 'https://docs.fastht.ml/tutorials/by_example.html#fasthtml-basics',\n",
       "  'score': 0.19991883635520935}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorStore.similarity_search('how to install fasthtml?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcf4c43-5bbe-43c5-892a-c2779d356931",
   "metadata": {},
   "source": [
    "### Generate Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "802a4cbd-ab30-4f70-96ac-81bfaf029859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "\n",
    "from langchain_core.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain_huggingface import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b90827a0-35c2-40f5-9e0d-7c39cc201f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_stream(chat_completion, llm):\n",
    "    if llm.startswith(\"gpt\"):\n",
    "        for chunk in chat_completion:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            if content is not None:\n",
    "                yield content\n",
    "    else:\n",
    "        for chunk in chat_completion:\n",
    "            yield chunk\n",
    "\n",
    "def prepare_response(chat_completion, stream, llm):\n",
    "    if stream:\n",
    "        return response_stream(chat_completion, llm)\n",
    "    else:\n",
    "        if llm.startswith(\"gpt\"):\n",
    "            return chat_completion.choices[0].message.content\n",
    "        else:\n",
    "            return chat_completion\n",
    "\n",
    "\n",
    "def get_client(llm):\n",
    "    if llm.startswith(\"gpt\"):\n",
    "        base_url = os.environ[\"OPENAI_API_BASE\"]\n",
    "        api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "        client = openai.OpenAI(base_url=base_url, api_key=api_key)\n",
    "    else:\n",
    "        #base_url = os.environ[\"HUGGINGFACEHUB_API_BASE\"]\n",
    "        api_key = \"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\" #os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
    "        client = HuggingFaceEndpoint(huggingfacehub_api_token=api_key, repo_id=llm)\n",
    "    \n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "24f01da8-b2e0-4578-b045-d8886457a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(\n",
    "    llm, temperature=0.0, stream=True, \n",
    "    system_content=\"\", assistant_content=\"\", user_content=\"\", \n",
    "    max_retries=1, retry_interval=60):\n",
    "    \"\"\"Generate response from an LLM\"\"\"\n",
    "    retry_count = 0\n",
    "    client = get_client(llm=llm)\n",
    "    \n",
    "    prompt = [(\"system\", system_content), (\"assistant\", assistant_content), (\"user\", user_content)]\n",
    "    messages = [{\"role\": role, \"content\": content} for role, content in prompt if content]\n",
    "\n",
    "    while retry_count <= max_retries:\n",
    "        try:\n",
    "            if llm.startswith(\"gpt\"):\n",
    "                chat_completion = client.chat.completions.create(\n",
    "                    model=llm,\n",
    "                    temperature=temperature,\n",
    "                    stream=stream,\n",
    "                    messages=messages,\n",
    "                )\n",
    "            else:\n",
    "                chat_completion = client.invoke(\n",
    "                    repo_id=llm,\n",
    "                    temperature=temperature,\n",
    "                    streaming=stream,\n",
    "                    input=messages,\n",
    "                )\n",
    "            return prepare_response(chat_completion, stream=stream, llm=llm)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Exception: {e}')\n",
    "            time.sleep(retry_interval) # default is pre-minute rate limits\n",
    "            retry_count += 1\n",
    "    return \"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "efec31ad-2e81-40ec-8a47-e023638fb434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Installing FastHTML FastHTML is just Python . Installation is often done with pip: pip install python-fasthtml', 'Install FastHTML For Mac, Windows and Linux, enter: pip install python-fasthtml', 'Installation pip install python-fasthtml', 'Installation Since fasthtml is a Python library, you can install it with: pip install python-fasthtml In the near future, we hope to add component libraries that can likewise be installed via pip .', 'FastHTML Basics FastHTML is just Python . You can install it with pip install python-fasthtml . Extensions/components built for it can likewise be distributed via PyPI or as simple Python files. The core usage of FastHTML is to define routes, and then to define what to do at each route. This is similar to the FastAPI web framework (in fact we implemented much of the functionality to match the FastAPI usage examples), but where FastAPI focuses on returning JSON data to build APIs, FastHTML']\n"
     ]
    }
   ],
   "source": [
    "context_results = vectorStore.similarity_search('how to install fasthtml?')\n",
    "context = [item[\"text\"] for item in context_results]\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c765a0f-794a-4856-a4f6-d4b65db4f55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/amrit/.cache/huggingface/token\n",
      "Login successful\n",
      "\n",
      "\n",
      "To install FastHTML, use the command `pip install python-fasthtml`. This command works on Mac, Windows, and Linux systems. FastHTML is a Python library, so it can be installed using pip."
     ]
    }
   ],
   "source": [
    "# Generate response\n",
    "query = 'how to install fasthtml?'\n",
    "response = generate_response(\n",
    "    llm=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    temperature=0.1,\n",
    "    stream=True,\n",
    "    system_content=\"Answer the query using the context provided. Be succinct.\",\n",
    "    user_content=f\"query: {query}, context: {context}\"\n",
    ")\n",
    "\n",
    "# Stream response\n",
    "for content in response:\n",
    "    print(content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f2b87b27-ecda-4675-ad50-7ced6eab02f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "\n",
    "def get_num_tokens(text):\n",
    "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return len(enc.encode(text))\n",
    "\n",
    "\n",
    "def trim(text, max_context_length):\n",
    "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return enc.decode(enc.encode(text)[:max_context_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4e86ab26-d7ed-4642-a982-fcc1b6ee828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryAgent:\n",
    "    def __init__(self, embedding_model_name=\"thenlper/gte-base\",\n",
    "                 llm=\"mistralai/Mistral-7B-Instruct-v0.3\", temperature=0.1, \n",
    "                 max_context_length=4096, system_content=\"\", assistant_content=\"\"\n",
    "                ):\n",
    "        # Embedding model\n",
    "        self.embedding_model = get_embedding_model(\n",
    "            embedding_model_name = embedding_model_name,\n",
    "            model_kwargs = {\"device\": \"cuda\"},\n",
    "            encode_kwargs = {\"device\": \"cuda\", \"batch_size\": 100}\n",
    "        )\n",
    "\n",
    "        # Context length (restrict input length to 50% of total context length)\n",
    "        max_context_length = int(0.5*max_context_length)\n",
    "\n",
    "        # LLM\n",
    "        self.llm = llm\n",
    "        self.temperature = temperature\n",
    "        self.context_length = max_context_length - get_num_tokens(system_content + assistant_content)\n",
    "        self.system_content = system_content\n",
    "        self.assistant_content = assistant_content\n",
    "\n",
    "    def __call__(self, query, num_chunks=5, stream=True):\n",
    "        # Get sources and context\n",
    "        # Initialize the vector store\n",
    "        #vectorStore = VectorStore(embedding_model=embedding_model_name, persist_directory=settings.VECTOR_STORE_DIR)\n",
    "        context_results = vectorStore.similarity_search(query=query)\n",
    "\n",
    "        # Generate response\n",
    "        context = [item[\"text\"] for item in context_results]\n",
    "        sources = [item[\"source\"] for item in context_results]\n",
    "        user_content = f\"query: {query}, context: {context}\"\n",
    "        answer = generate_response(\n",
    "            llm=self.llm,\n",
    "            temperature=self.temperature,\n",
    "            stream=stream,\n",
    "            system_content=self.system_content,\n",
    "            assistant_content=self.assistant_content,\n",
    "            user_content=trim(user_content, self.context_length))\n",
    "\n",
    "        # Result\n",
    "        result = {\n",
    "            \"question\": query,\n",
    "            \"sources\": sources,\n",
    "            \"answer\": answer,\n",
    "            \"llm\": self.llm,\n",
    "        }\n",
    "        return result\n",
    "\n",
    "# context_results = vectorStore.similarity_search('how to install fasthtml?')\n",
    "# context = [item[\"text\"] for item in context_results]\n",
    "\n",
    "# query = 'how to install fasthtml?'\n",
    "# response = generate_response(\n",
    "#     llm=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "#     temperature=0.1,\n",
    "#     stream=True,\n",
    "#     system_content=\"Answer the query using the context provided. Be succinct.\",\n",
    "#     user_content=f\"query: {query}, context: {context}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e7b338aa-5fbf-496c-9f14-3988eb854933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from config.config import MAX_CONTEXT_LENGTHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "10834023-cac3-41c2-a103-5d42d1c712f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_name = \"thenlper/gte-base\"\n",
    "llm = \"mistralai/Mistral-7B-Instruct-v0.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "95483e86-1447-4c51-88ee-2cd140efcc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: thenlper/gte-base\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/amrit/.cache/huggingface/token\n",
      "Login successful\n",
      "{\n",
      "  \"question\": \"how to install fasthtml?\",\n",
      "  \"sources\": [\n",
      "    \"https://docs.fastht.ml/tutorials/tutorial_for_web_devs.html#installing-fasthtml\",\n",
      "    \"https://docs.fastht.ml/tutorials/e2e.html#install-fasthtml\",\n",
      "    \"https://docs.fastht.ml/tutorials/quickstart_for_web_devs.html#installation\",\n",
      "    \"https://docs.fastht.ml/index.html#installation\",\n",
      "    \"https://docs.fastht.ml/tutorials/by_example.html#fasthtml-basics\"\n",
      "  ],\n",
      "  \"answer\": \"\\n\\nTo install FastHTML, use the command `pip install python-fasthtml`. This command works on Mac, Windows, and Linux systems. FastHTML is a Python library, so it can be installed using pip.\",\n",
      "  \"llm\": \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = 'how to install fasthtml?'\n",
    "system_content = \"Answer the query using the context provided. Be succinct.\"\n",
    "agent = QueryAgent(\n",
    "    embedding_model_name=embedding_model_name,\n",
    "    llm=llm,\n",
    "    max_context_length=MAX_CONTEXT_LENGTHS[llm],\n",
    "    system_content=system_content)\n",
    "result = agent(query=query, stream=False)\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f2ecd1-16c8-4897-bf75-f1574a0cc235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
