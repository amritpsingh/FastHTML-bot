{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b517a5-05e9-41d4-aaf2-be9080bb2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Dict\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b16e010-8983-49a4-b9c9-fb05254a532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_sections(markdown_content: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Extract sections from markdown content.\n",
    "    \"\"\"\n",
    "    # Convert markdown to HTML\n",
    "    html = markdown.markdown(markdown_content)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    sections = []\n",
    "    current_section = {\"title\": \"Introduction\", \"content\": \"\"}\n",
    "    \n",
    "    for element in soup.find_all(['h1', 'h2', 'h3', 'p']):\n",
    "        if element.name in ['h1', 'h2', 'h3']:\n",
    "            if current_section[\"content\"].strip():\n",
    "                sections.append(current_section)\n",
    "            current_section = {\"title\": element.text.strip(), \"content\": \"\"}\n",
    "        else:\n",
    "            current_section[\"content\"] += element.text + \"\\n\"\n",
    "    \n",
    "    if current_section[\"content\"].strip():\n",
    "        sections.append(current_section)\n",
    "    \n",
    "    return sections\n",
    "\n",
    "def create_chunks(text: str, chunk_size: int = 300, overlap: int = 50) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split text into overlapping chunks.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "def process_markdown_file(file_path: str, base_url: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Process a markdown file and return a list of chunks with their sources.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        if not content.strip():\n",
    "            print(f\"Warning: File {file_path} is empty.\")\n",
    "            return []\n",
    "        \n",
    "        sections = extract_sections(content)\n",
    "        result = []\n",
    "        \n",
    "        for section in sections:\n",
    "            section_id = re.sub(r'\\W+', '-', section['title'].lower())\n",
    "            url = f\"{base_url}#{section_id}\"\n",
    "            \n",
    "            chunks = create_chunks(section['content'])\n",
    "            \n",
    "            for chunk in chunks:\n",
    "                result.append({\n",
    "                    \"source\": url,\n",
    "                    \"text\": chunk\n",
    "                })\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def process_all_markdown_files(directory: str, base_url: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Process all markdown files in a directory and its subdirectories.\n",
    "    \"\"\"\n",
    "    all_chunks = []\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Error: Directory {directory} does not exist.\")\n",
    "        return all_chunks\n",
    "    \n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.md'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                relative_path = os.path.relpath(file_path, directory)\n",
    "                file_url = f\"{base_url}/{relative_path.replace('.md', '.html')}\"\n",
    "                \n",
    "                print(f\"Processing file: {file_path}\")\n",
    "                chunks = process_markdown_file(file_path, file_url)\n",
    "                all_chunks.extend(chunks)\n",
    "    \n",
    "    if not all_chunks:\n",
    "        print(f\"Warning: No chunks were extracted from {directory}.\")\n",
    "    \n",
    "    return all_chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dab2fdc9-3f0d-4029-ae95-50d15bad3892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing directory: ./docs\n",
      "Base URL: https://docs.fastht.ml\n",
      "Processing file: ./docs/index-html.md\n",
      "Processing file: ./docs/index-html-md.md\n",
      "Processing file: ./docs/ref/defining-xt-component.md\n",
      "Processing file: ./docs/ref/live-reload-html-md.md\n",
      "Processing file: ./docs/ref/live-reload-html.md\n",
      "Processing file: ./docs/ref/defining-xt-component-md.md\n",
      "Processing file: ./docs/ref/defining-xt-component-html.md\n",
      "Processing file: ./docs/.ipynb_checkpoints/index-html-md-checkpoint.md\n",
      "Processing file: ./docs/.ipynb_checkpoints/index-html-checkpoint.md\n",
      "Processing file: ./docs/api/js-html.md\n",
      "Processing file: ./docs/api/pico-html-md.md\n",
      "Processing file: ./docs/api/components-html-md.md\n",
      "Processing file: ./docs/api/core-html.md\n",
      "Processing file: ./docs/api/xtend-html.md\n",
      "Processing file: ./docs/api/xtend-html-md.md\n",
      "Processing file: ./docs/api/pico-html.md\n",
      "Processing file: ./docs/api/oauth-html-md.md\n",
      "Processing file: ./docs/api/core-html-md.md\n",
      "Processing file: ./docs/api/fastapp-html-md.md\n",
      "Processing file: ./docs/api/oauth-html.md\n",
      "Processing file: ./docs/api/components-html.md\n",
      "Processing file: ./docs/api/cli-html.md\n",
      "Processing file: ./docs/api/js-html-md.md\n",
      "Processing file: ./docs/api/cli-html-md.md\n",
      "Processing file: ./docs/api/fastapp-html.md\n",
      "Processing file: ./docs/api/.ipynb_checkpoints/cli-html-md-checkpoint.md\n",
      "Processing file: ./docs/api/.ipynb_checkpoints/cli-html-checkpoint.md\n",
      "Processing file: ./docs/tutorials/index-html.md\n",
      "Processing file: ./docs/tutorials/quickstart-for-web-devs-html-md.md\n",
      "Processing file: ./docs/tutorials/tutorial-for-web-devs-html-md.md\n",
      "Processing file: ./docs/tutorials/index-md.md\n",
      "Processing file: ./docs/tutorials/tutorial-for-web-devs-html.md\n",
      "Processing file: ./docs/tutorials/e2e-html-md.md\n",
      "Processing file: ./docs/tutorials/by-example-html.md\n",
      "Processing file: ./docs/tutorials/by-example-html-md.md\n",
      "Processing file: ./docs/tutorials/e2e-html.md\n",
      "Processing file: ./docs/tutorials/quickstart-for-web-devs-html.md\n",
      "Processing file: ./docs/tutorials/.ipynb_checkpoints/by-example-html-md-checkpoint.md\n",
      "Processing file: ./docs/tutorials/.ipynb_checkpoints/by-example-html-checkpoint.md\n",
      "Processing file: ./docs/cdn-cgi/l/email-protection.md\n",
      "Processing file: ./docs/explains/explaining-xt-components-html.md\n",
      "Processing file: ./docs/explains/routes-html.md\n",
      "Processing file: ./docs/explains/explaining-xt-components-html-md.md\n",
      "Processing file: ./docs/explains/oauth-html-md.md\n",
      "Processing file: ./docs/explains/faq-html-md.md\n",
      "Processing file: ./docs/explains/oauth-html.md\n",
      "Processing file: ./docs/explains/faq-html.md\n",
      "Processing file: ./docs/explains/routes-html-md.md\n",
      "Total chunks extracted: 536\n",
      "Example chunk:\n",
      "{'source': 'https://docs.fastht.ml/index-html.html#introduction', 'text': 'Title: FastHTML – fasthtml URL Source: https://docs.fastht.ml/index.html Markdown Content: Welcome to the official FastHTML documentation. FastHTML is a new next-generation web framework for fast, scalable web applications with minimal, compact code. It’s designed to be: FastHTML apps are just Python code, so you can use FastHTML with the full power of the Python language and ecosystem. FastHTML’s functionality maps 1:1 directly to HTML and HTTP, but allows them to be encapsulated using good software engineering practices—so you’ll need to understand these foundations to use this library fully. To understand how and why this works, please read this first: about.fastht.ml.'}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    directory = './docs'\n",
    "    base_url = 'https://docs.fastht.ml'\n",
    "    \n",
    "    print(f\"Processing directory: {directory}\")\n",
    "    print(f\"Base URL: {base_url}\")\n",
    "    \n",
    "    all_chunks = process_all_markdown_files(directory, base_url)\n",
    "    print(f\"Total chunks extracted: {len(all_chunks)}\")\n",
    "    \n",
    "    if all_chunks:\n",
    "        print(\"Example chunk:\")\n",
    "        print(all_chunks[0])\n",
    "    else:\n",
    "        print(\"No chunks were extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c3f90e1-7a65-4d64-872b-64eefe8fe62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'source': 'https://docs.fastht.ml/index-html.html#installation', 'text': 'Since fasthtml is a Python library, you can install it with: pip install python-fasthtml In the near future, we hope to add component libraries that can likewise be installed via pip.'}, {'source': 'https://docs.fastht.ml/index-html.html#usage', 'text': 'For a minimal app, create a file “main.py” as follows: ``` from fasthtml.common import * app,rt = fast_app() @rt(\\'/\\') def get(): return Div(P(\\'Hello World!\\'), hx_get=\"/change\") serve() ``` Running the app with python main.py prints out a link to your running app: http://localhost:5001. Visit that link in your browser and you should see a page with the text “Hello World!”. Congratulations, you’ve just created your first FastHTML app! Adding interactivity is surprisingly easy, thanks to HTMX. Modify the file to add this function: @rt(\\'/change\\') def get(): return P(\\'Nice to be here!\\') You now have a page with a clickable element that changes the text when clicked. When clicking on this link, the server will respond with an “HTML partial”—that is, just a snippet of HTML which will be inserted into the existing page. In this case, the returned element will replace the original P element (since that’s the default behavior of HTMX) with the new version returned by the second route. This “hypermedia-based” approach to web development is a powerful way to build web applications.'}]\n"
     ]
    }
   ],
   "source": [
    "print(all_chunks[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3962f06-04de-4c78-8b10-9597d45889ac",
   "metadata": {},
   "source": [
    "### create_embeddings_and_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150d20f-f098-454d-a5b4-9ee799b19dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict\n",
    "import uuid\n",
    "\n",
    "# Import the markdown processing functions\n",
    "from markdown_processor_debug import process_all_markdown_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55890db-a118-41f6-897d-569de8d43d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_and_store(chunks: List[Dict[str, str]], collection_name: str = \"fasthtml_docs\"):\n",
    "    # Initialize Chroma client\n",
    "    client = chromadb.Client()\n",
    "\n",
    "    # Create a collection\n",
    "    embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
    "    collection = client.create_collection(name=collection_name, embedding_function=embedding_function)\n",
    "\n",
    "    # Initialize the embedding model\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    # Prepare data for Chroma\n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        documents.append(chunk['text'])\n",
    "        metadatas.append({\"source\": chunk['source']})\n",
    "        ids.append(str(uuid.uuid4()))  # Generate a unique ID for each chunk\n",
    "\n",
    "    # Create embeddings\n",
    "    embeddings = model.encode(documents)\n",
    "\n",
    "    # Add to Chroma DB\n",
    "    collection.add(\n",
    "        documents=documents,\n",
    "        embeddings=embeddings.tolist(),\n",
    "        metadatas=metadatas,\n",
    "        ids=ids\n",
    "    )\n",
    "\n",
    "    print(f\"Added {len(documents)} chunks to Chroma DB collection '{collection_name}'\")\n",
    "\n",
    "    return collection\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Process markdown files and get chunks\n",
    "    directory = './docs/DocsFasthtMl'\n",
    "    base_url = 'https://docs.fastht.ml'\n",
    "    \n",
    "    print(f\"Processing directory: {directory}\")\n",
    "    print(f\"Base URL: {base_url}\")\n",
    "    \n",
    "    all_chunks = process_all_markdown_files(directory, base_url)\n",
    "    print(f\"Total chunks extracted: {len(all_chunks)}\")\n",
    "\n",
    "    if all_chunks:\n",
    "        # Create embeddings and store in Chroma DB\n",
    "        collection = create_embeddings_and_store(all_chunks)\n",
    "\n",
    "        # Example query to test the embeddings\n",
    "        query = \"What is FastHTML?\"\n",
    "        results = collection.query(\n",
    "            query_texts=[query],\n",
    "            n_results=2\n",
    "        )\n",
    "\n",
    "        print(\"\\nExample query results:\")\n",
    "        for i, (document, metadata) in enumerate(zip(results['documents'][0], results['metadatas'][0])):\n",
    "            print(f\"\\nResult {i+1}:\")\n",
    "            print(f\"Source: {metadata['source']}\")\n",
    "            print(f\"Text: {document[:200]}...\")  # Print first 200 characters\n",
    "    else:\n",
    "        print(\"No chunks were extracted. Please check your markdown files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
